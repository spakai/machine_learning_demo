"""
Generate a training summary through the GitHub Models inference API.

This is optional tooling to illustrate how GitHub Models can complement the
regression workflow by turning raw metrics into a natural-language report.
"""
from __future__ import annotations

import argparse
import json
import os
from pathlib import Path
from typing import Any, Dict

import httpx

DEFAULT_ENDPOINT = "https://models.github.ai/inference/chat/completions"
DEFAULT_MODEL = "gpt-4o-mini"


def build_prompt(metrics: Dict[str, Any], data_preview: str) -> str:
    return (
        "You are assisting with a tiny regression demo that predicts ice-cream sales "
        "from ambient temperature.\n"
        f"The current metrics are: {json.dumps(metrics)}\n"
        f"A preview of the dataset rows:\n{data_preview}\n"
        "Highlight the top priorities for the next training iteration.\n"
        "List three hypotheses to improve test RMSE given these numbers.\n"
        "Respond in Markdown with two sections: '## Priorities' (bullet list) and "
        "'## Hypotheses' (numbered list). Keep the guidance concise and actionable."
    )


def read_metrics(metrics_path: Path) -> Dict[str, Any]:
    if not metrics_path.exists():
        raise FileNotFoundError(f"Metrics file not found at {metrics_path}. Run training first.")
    return json.loads(metrics_path.read_text())


def read_dataset_preview(dataset_path: Path, limit: int = 5) -> str:
    lines = dataset_path.read_text().strip().splitlines()
    header, rows = lines[0], lines[1 : limit + 1]
    return "\n".join([header] + rows)


def request_summary(
    token: str,
    endpoint: str,
    model: str,
    prompt: str,
) -> str:
    headers = {
        "Authorization": f"Bearer {token}",
        "Content-Type": "application/json",
        "X-GitHub-Api-Version": "2023-07-01",
    }
    payload = {
        "model": model,
        "messages": [
            {"role": "system", "content": "You are a concise technical writer."},
            {"role": "user", "content": prompt},
        ],
        "temperature": 0.3,
    }
    response = httpx.post(endpoint, headers=headers, json=payload, timeout=60)
    response.raise_for_status()
    completion = response.json()
    return completion["choices"][0]["message"]["content"]


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="Generate a summary of the regression model using GitHub Models."
    )
    parser.add_argument(
        "--metrics-path",
        type=Path,
        default=Path("models/metrics.json"),
        help="Path to the metrics JSON generated by training.",
    )
    parser.add_argument(
        "--dataset-path",
        type=Path,
        default=Path("data/icecream_sales.csv"),
        help="Path to the dataset for context in the prompt.",
    )
    parser.add_argument(
        "--endpoint",
        default=os.environ.get("GITHUB_MODELS_ENDPOINT", DEFAULT_ENDPOINT),
        help="GitHub Models endpoint.",
    )
    parser.add_argument(
        "--model",
        default=os.environ.get("GITHUB_MODELS_MODEL", DEFAULT_MODEL),
        help="Model identifier to invoke, e.g. gpt-4o-mini or gpt-4.1-mini.",
    )
    return parser.parse_args()


def main() -> None:
    args = parse_args()
    token = os.environ.get("GITHUB_MODELS_TOKEN") or os.environ.get("GITHUB_TOKEN")
    if not token:
        raise RuntimeError("Set GITHUB_MODELS_TOKEN or GITHUB_TOKEN with model scope.")
    metrics = read_metrics(args.metrics_path)
    preview = read_dataset_preview(args.dataset_path)
    prompt = build_prompt(metrics, preview)
    summary = request_summary(token, args.endpoint, args.model, prompt)
    print(summary)


if __name__ == "__main__":
    main()
